{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ef67329-7f99-451a-8bdb-e91e369d034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/spark-3.3.2-bin-hadoop3/python (3.3.2)\n",
      "Collecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: py4j\n",
      "Successfully installed py4j-0.10.9.5\n",
      "+--------------------+------+---+--------------------+-----------+-------------+\n",
      "|               after|before| op|              source|transaction|        ts_ms|\n",
      "+--------------------+------+---+--------------------+-----------+-------------+\n",
      "|{100.0, Ford, 201...|  null|  r|{mysql, inventory...|       null|1679965843817|\n",
      "+--------------------+------+---+--------------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Inventory ETL\") \\\n",
    "    .config(\"spark.sql.parquet.datetimeRebaseModeInWrite\", \"LEGACY\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:3.2.0\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Set the necessary AWS credentials\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"minio\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"minio123\")\n",
    "spark.sparkContext._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"minio:9000\")\n",
    "\n",
    "# Set the path to the JSON file\n",
    "get_users_file = \"s3a://warehouse/inventory/dbserver1.inventory.customers/partition=0/*.json\"\n",
    "\n",
    "# Read the JSON file\n",
    "raw_data = spark.read \\\n",
    "    .format(\"json\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .json(get_users_file)\n",
    "\n",
    "# Display raw data\n",
    "raw_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34027a94-39cd-4dde-9bc0-43e99417bd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the data\n",
    "silver_data = raw_data.select(\n",
    "    \"after.id\",\n",
    "    \"after.plate_number\",\n",
    "    \"after.car_make\",\n",
    "    \"after.car_year\",\n",
    "    \"after.owner_name\",\n",
    "    \"after.owner_address\",\n",
    "    \"after.owner_phone_number\",\n",
    "    \"after.subscription_status\",\n",
    "    \"after.subscription_start\",\n",
    "    \"after.subscription_end\",\n",
    "    \"after.balance\",\n",
    "    \"after.timestamp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e36db0-4039-4792-ad0a-c81d8d8a3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data.write.parquet(\"s3a://warehouse/inventory/silver_data\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc38035e-bccc-419c-9f5d-784b6d8bf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "silver_data = spark.read.parquet(\"s3a://warehouse/inventory/silver_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10794ce4-7037-487d-a163-e3f344047589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------+--------+----------+--------------------+------------------+-------------------+------------------+----------------+-------+--------------------+\n",
      "|                  id|plate_number|car_make|car_year|owner_name|       owner_address|owner_phone_number|subscription_status|subscription_start|subscription_end|balance|           timestamp|\n",
      "+--------------------+------------+--------+--------+----------+--------------------+------------------+-------------------+------------------+----------------+-------+--------------------+\n",
      "|5a5c562e-4386-44a...|    7695-OOO|    Ford|    2012|    Stefen|92834 Kim Unions\\...|      +14385064453|             active|              null|            null|  100.0|2023-03-03T14:37:49Z|\n",
      "+--------------------+------------+--------+--------+----------+--------------------+------------------+-------------------+------------------+----------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3747067d-5514-4222-af58-4e5ec5d1d1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twilio\n",
      "  Downloading twilio-7.17.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from twilio) (2.28.1)\n",
      "Requirement already satisfied: PyJWT<3.0.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from twilio) (2.5.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.8/site-packages (from twilio) (2022.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->twilio) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->twilio) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.0.0->twilio) (3.4)\n",
      "Installing collected packages: twilio\n",
      "Successfully installed twilio-7.17.0\n",
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-8.0.32-cp38-cp38-manylinux1_x86_64.whl (23.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.5/23.5 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<=3.20.3,>=3.11.0\n",
      "  Downloading protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf, mysql-connector-python\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.21.7\n",
      "    Uninstalling protobuf-4.21.7:\n",
      "      Successfully uninstalled protobuf-4.21.7\n",
      "Successfully installed mysql-connector-python-8.0.32 protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "!pip install twilio\n",
    "!pip install mysql-connector-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cdf3ad9-c375-4d99-b528-633a65d026a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt, timedelta, timezone\n",
    "import pytz\n",
    "from twilio.rest import Client\n",
    "from pyspark.sql import Row\n",
    "from datetime import datetime, timezone\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import BooleanType\n",
    "import datetime\n",
    "import mysql.connector\n",
    "from typing import Optional\n",
    "\n",
    "# Additional imports\n",
    "from mysql.connector import Error\n",
    "\n",
    "TWILIO_ACCOUNT_SID = '",
    "TWILIO_AUTH_TOKEN =  '" ,
    "TWILIO_PHONE_NUMBER = '",
    "\n",
    "client = Client(TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN)\n",
    "silver_data = spark.read.parquet(\"s3a://warehouse/inventory/silver_data\")\n",
    "\n",
    "def get_rate_for_customer(timestamp, subscription_status):\n",
    "    if subscription_status == 'active':\n",
    "        if 0 <= timestamp.hour < 6 or 11 <= timestamp.hour < 16:\n",
    "            return 2.99\n",
    "        elif 6 <= timestamp.hour < 11 or 16 <= timestamp.hour < 23:\n",
    "            return 3.99\n",
    "    else:\n",
    "        return 9.99\n",
    "\n",
    "    # Add a default rate value to avoid NoneType issues\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def is_subscription_active(subscription_start: dt, subscription_end: dt, current_time: dt) -> bool:\n",
    "    return subscription_start <= current_time <= subscription_end\n",
    "\n",
    "def get_subscription_status(subscription_end: dt, current_time: dt) -> bool:\n",
    "    grace_period = timedelta(days=7)\n",
    "    return current_time <= subscription_end + grace_period\n",
    "\n",
    "\n",
    "def send_sms(phone_number, message):\n",
    "    try:\n",
    "        client.messages.create(\n",
    "            body=message,\n",
    "            from_=TWILIO_PHONE_NUMBER,\n",
    "            to=phone_number\n",
    "        )\n",
    "        print(f\"SMS sent to {phone_number}: {message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error sending SMS: {e}\")\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def is_valid_balance(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "valid_balance_udf = udf(is_valid_balance, BooleanType())\n",
    "\n",
    "silver_data = silver_data.filter(valid_balance_udf(col(\"balance\")))\n",
    "\n",
    "# Database configuration\n",
    "db_config = {\n",
    "    \"host\": \"mysql\",\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"debezium\",\n",
    "    \"database\": \"inventory\"\n",
    "}\n",
    "\n",
    "def update_customer_balance(customer_id, new_balance):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(**db_config)\n",
    "        cursor = connection.cursor()\n",
    "        update_query = \"UPDATE customers SET balance = %s WHERE id = %s\"\n",
    "        cursor.execute(update_query, (new_balance, customer_id))\n",
    "        connection.commit()\n",
    "        print(f\"Updated balance for customer {customer_id}: {new_balance}\")\n",
    "    except Error as e:\n",
    "        print(f\"Error updating balance: {e}\")\n",
    "    finally:\n",
    "        if connection.is_connected():\n",
    "            cursor.close()\n",
    "            connection.close() \n",
    "\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def safe_date_conversion(date_string: Optional[str]) -> dt:\n",
    "    if date_string is None or not isinstance(date_string, str):\n",
    "        return dt(1970, 1, 1, tzinfo=timezone.utc)\n",
    "    try:\n",
    "        return dt.fromisoformat(date_string[:-1]).replace(tzinfo=timezone.utc)\n",
    "    except ValueError:\n",
    "        return dt(1970, 1, 1, tzinfo=timezone.utc)\n",
    "\n",
    "def process_plate(row: Row) -> None:\n",
    "    print(f\"Processing plate: {row.plate_number}\")\n",
    "    current_time = dt.now(timezone.utc)\n",
    "    try:\n",
    "        plate_timestamp = dt.fromisoformat(row.timestamp[:-1]).replace(tzinfo=timezone.utc)\n",
    "    except ValueError:\n",
    "        plate_timestamp = dt.fromtimestamp(0, timezone.utc)\n",
    "\n",
    "    subscription_start = safe_date_conversion(row.subscription_start)\n",
    "    subscription_end = safe_date_conversion(row.subscription_end)\n",
    "\n",
    "    is_active = is_subscription_active(subscription_start, subscription_end, current_time)\n",
    "    rate = get_rate_for_customer(plate_timestamp, row.subscription_status)\n",
    "\n",
    "    balance = float(row.balance)\n",
    "    new_balance = balance - rate\n",
    "\n",
    "    if row.subscription_status == 'none':\n",
    "        message = f\"Dear {row.owner_name}, your car with plate number {row.plate_number} is not registered. The rate of ${rate} has been charged for your recent passage. Your new balance is ${new_balance:.2f}.\"\n",
    "        send_sms(row.owner_phone_number, message)\n",
    "    elif is_active:  # Changed from row.subscription_status == 'active'\n",
    "        message = f\"Dear {row.owner_name}, your subscription is active. The rate of ${rate} has been charged for your recent passage. Your new balance is ${new_balance:.2f}.\"\n",
    "        send_sms(row.owner_phone_number, message)\n",
    "    elif not get_subscription_status(subscription_end, current_time):\n",
    "        message = f\"Dear {row.owner_name}, your subscription has expired. The rate of ${rate} has been charged for your recent passage. Your new balance is ${new_balance:.2f}.\"\n",
    "        send_sms(row.owner_phone_number, message)\n",
    "\n",
    "        update_customer_balance(row.id, new_balance)\n",
    "\n",
    "silver_data.foreach(process_plate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8beefe0b-5fae-43d7-a903-d82a8cab1eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsample_data = Row(\\n    id='5a5c562e-4386-44ad-bf6f-bab91081781e',\\n    plate_number='7695-OOO',\\n    car_make='Ford',\\n    car_year=2012,\\n    owner_name='Becky Smith',\\n    owner_address='92834 Kim Unions\\nPort Harryport, MD 61729',\\n    owner_phone_number='+14385064453',\\n    subscription_status='none',\\n    subscription_start=None,\\n    subscription_end=None,\\n    balance=100.0,  # Replace 'Exc=' with a valid float value\\n    timestamp='2023-03-03T14:37:49Z',\\n    rate=9.99\\n)\\n\\nprocess_plate(sample_data)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "sample_data = Row(\n",
    "    id='5a5c562e-4386-44ad-bf6f-bab91081781e',\n",
    "    plate_number='7695-OOO',\n",
    "    car_make='Ford',\n",
    "    car_year=2012,\n",
    "    owner_name='Becky Smith',\n",
    "    owner_address='92834 Kim Unions\\nPort Harryport, MD 61729',\n",
    "    owner_phone_number='+14354123654',\n",
    "    subscription_status='none',\n",
    "    subscription_start=None,\n",
    "    subscription_end=None,\n",
    "    balance=100.0,  # Replace 'Exc=' with a valid float value\n",
    "    timestamp='2023-03-03T14:37:49Z',\n",
    "    rate=9.99\n",
    ")\n",
    "\n",
    "process_plate(sample_data)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84eb738c-e811-44e1-84e5-a56002973ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+\n",
      "|subscription_status|count|\n",
      "+-------------------+-----+\n",
      "|             active|    1|\n",
      "+-------------------+-----+\n",
      "\n",
      "Daily Metrics:\n",
      "+----------+--------------+-------------+\n",
      "|      date|total_passages|total_revenue|\n",
      "+----------+--------------+-------------+\n",
      "|2023-03-03|             1|         3.99|\n",
      "+----------+--------------+-------------+\n",
      "\n",
      "Weekly Metrics:\n",
      "+----+------------+--------------+-------------+\n",
      "|year|week_of_year|total_passages|total_revenue|\n",
      "+----+------------+--------------+-------------+\n",
      "|2023|           9|             1|         3.99|\n",
      "+----+------------+--------------+-------------+\n",
      "\n",
      "Monthly Metrics:\n",
      "+----+-----+--------------+-------------+\n",
      "|year|month|total_passages|total_revenue|\n",
      "+----+-----+--------------+-------------+\n",
      "|2023|    3|             1|         3.99|\n",
      "+----+-----+--------------+-------------+\n",
      "\n",
      "Quarterly Metrics:\n",
      "+----+-------+--------------+-------------+\n",
      "|year|quarter|total_passages|total_revenue|\n",
      "+----+-------+--------------+-------------+\n",
      "|2023|      1|             1|         3.99|\n",
      "+----+-------+--------------+-------------+\n",
      "\n",
      "Yearly Metrics:\n",
      "+----+--------------+-------------+\n",
      "|year|total_passages|total_revenue|\n",
      "+----+--------------+-------------+\n",
      "|2023|             1|         3.99|\n",
      "+----+--------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gold_data = silver_data.groupBy(\"subscription_status\").count()\n",
    "\n",
    "gold_data.show()\n",
    "\n",
    "gold_data.write.parquet(\"s3a://warehouse/inventory/gold_data\", mode=\"overwrite\")\n",
    "\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "class MetricsAdapter:\n",
    "    def __init__(self, silver_table, warehouse_path):\n",
    "        self.silver_table = silver_table\n",
    "        self.warehouse_path = warehouse_path\n",
    "        \n",
    "    def show_metrics(self):\n",
    "        daily_metrics = spark.read.format('delta').load(self.warehouse_path + '/gold/daily_metrics')\n",
    "        weekly_metrics = spark.read.format('delta').load(self.warehouse_path + '/gold/weekly_metrics')\n",
    "        monthly_metrics = spark.read.format('delta').load(self.warehouse_path + '/gold/monthly_metrics')\n",
    "        quarterly_metrics = spark.read.format('delta').load(self.warehouse_path + '/gold/quarterly_metrics')\n",
    "        yearly_metrics = spark.read.format('delta').load(self.warehouse_path + '/gold/yearly_metrics')\n",
    "        subscription_status_count = silver_data.groupBy(\"subscription_status\").count()\n",
    "\n",
    "        print(\"Daily Metrics:\")\n",
    "        daily_metrics.show(5)\n",
    "\n",
    "        print(\"Weekly Metrics:\")\n",
    "        weekly_metrics.show(5)\n",
    "\n",
    "        print(\"Monthly Metrics:\")\n",
    "        monthly_metrics.show(5)\n",
    "\n",
    "        print(\"Quarterly Metrics:\")\n",
    "        quarterly_metrics.show(5)\n",
    "\n",
    "        print(\"Yearly Metrics:\")\n",
    "        yearly_metrics.show(5)    \n",
    "\n",
    "    def transform(self):\n",
    "        # Calculate the week, month, quarter, and year from the timestamp\n",
    "        time_based_metrics = self.silver_table.withColumn(\"date\", F.to_date(\"timestamp\")) \\\n",
    "            .withColumn(\"year\", F.year(\"timestamp\")) \\\n",
    "            .withColumn(\"quarter\", F.quarter(\"timestamp\")) \\\n",
    "            .withColumn(\"month\", F.month(\"timestamp\")) \\\n",
    "            .withColumn(\"week_of_year\", F.weekofyear(\"timestamp\")) \\\n",
    "            .withColumn(\"total_passages\", F.lit(1)) \\\n",
    "            .withColumn(\"total_revenue\", F.when(self.silver_table.timestamp.substr(12, 2).cast(\"int\") < 12, 2.99).otherwise(3.99))\n",
    "\n",
    "\n",
    "        # Daily metrics\n",
    "        daily_metrics = time_based_metrics.groupBy(\"date\").agg(\n",
    "            F.count(\"*\").alias(\"total_passages\"),\n",
    "            F.sum(F.when(time_based_metrics.timestamp.substr(12, 2).cast(\"int\") < 12, 2.99).otherwise(3.99)).alias(\"total_revenue\")\n",
    "        )\n",
    "        daily_metrics.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save(self.warehouse_path + '/gold/daily_metrics')\n",
    "\n",
    "        # Weekly metrics\n",
    "        weekly_metrics = time_based_metrics.groupBy(\"year\", \"week_of_year\").agg(\n",
    "            F.sum(\"total_passages\").alias(\"total_passages\"),\n",
    "            F.sum(\"total_revenue\").alias(\"total_revenue\")\n",
    "        )\n",
    "        weekly_metrics.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save(self.warehouse_path + '/gold/weekly_metrics')\n",
    "\n",
    "        # Monthly metrics\n",
    "        monthly_metrics = time_based_metrics.groupBy(\"year\", \"month\").agg(\n",
    "            F.sum(\"total_passages\").alias(\"total_passages\"),\n",
    "            F.sum(\"total_revenue\").alias(\"total_revenue\")\n",
    "        )\n",
    "        monthly_metrics.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save(self.warehouse_path + '/gold/monthly_metrics')\n",
    "\n",
    "        # Quarterly metrics\n",
    "        quarterly_metrics = time_based_metrics.groupBy(\"year\", \"quarter\").agg(\n",
    "            F.sum(\"total_passages\").alias(\"total_passages\"),\n",
    "            F.sum(\"total_revenue\").alias(\"total_revenue\")\n",
    "        )\n",
    "        quarterly_metrics.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save(self.warehouse_path + '/gold/quarterly_metrics')\n",
    "\n",
    "        # Yearly metrics\n",
    "        yearly_metrics = time_based_metrics.groupBy(\"year\").agg(\n",
    "            F.sum(\"total_passages\").alias(\"total_passages\"),\n",
    "            F.sum(\"total_revenue\").alias(\"total_revenue\")\n",
    "        )\n",
    "        yearly_metrics.write.format('delta').mode('overwrite').option(\"mergeSchema\", \"true\").save(self.warehouse_path + '/gold/yearly_metrics')\n",
    "\n",
    "# Example usage\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "silver_data = spark.read.parquet(\"s3a://warehouse/inventory/silver_data\")\n",
    "warehouse_path = \"s3a://warehouse/inventory/gold_data\"\n",
    "metrics_adapter = MetricsAdapter(silver_data, warehouse_path)\n",
    "metrics_adapter.transform()\n",
    "\n",
    "metrics_adapter.show_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9079a66c-d57f-4ab2-a52d-3ee7a2929490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
